# Twitter-Sentiment-Analysis

Created an API token to fetch the Dataset from Kaggle of 1.6M tweets to carry out sentiment analysis. CSV file was read into a dataframe using pandas
The approach was to remove any unncessary information and formattings first, cheak for any empty values, clean up and relabel data into meaningful context as part of pre-processing.For this the nltk.corpus module helped download and remove any stopwords from the tweets. Regular expression module helped removing anything that wasn't in the alphabet- like numbers and special characters since it doesn't help the model in learning anything about the sentiment. Stemming was conducted on every word of every tweet to further reduce words into their root words and stringed together individually. This would make it easier for the model to learn and assign values to each word and hence find correlation if a particular word makes a tweet positive or negative. This data was further split into training and test sets with 80% of the data going into training and the remaining 20% as test. Since ML models only understands numbers, these root words had to be converted into some numerical values for the model to understand. This was achieved by using the sklearn.feature_extraction.text library and importing the TfidfVectorizer module. After this is done, the LOGISTIC REGRESSION model is trained and to evaluate the model accuracy score is the metrics that was used on training and test data. The model turned out to be 79% and 77% accurate.
